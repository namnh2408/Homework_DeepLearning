{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildmodel(VOCABULARY):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape = (SEQ_LENGTH, 1), return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(VOCABULARY, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('D:\\Prediction_RNN\\text_data.txt', encoding = 'utf8')\n",
    "raw_text = file.read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '#', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff']\n",
      "['\\n', ' ', '!', '$', '%', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)\n",
    "bad_chars = ['#', '*', '@', '_', '\\ufeff']\n",
    "for i in range(len(bad_chars)):\n",
    "    raw_text = raw_text.replace(bad_chars[i],\"\")\n",
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)\n",
    "VOCABULARY = len(chars)\n",
    "\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'D:\\Prediction_RNN\\saved_models\\weights-improvement-49-1.3420.hdf5'\n",
    "model = buildmodel(VOCABULARY)\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_text = ' the sun did not shine, it was too wet to play, so we sat in the house all that cold, cold wet day. '# we sat here we two and we said how we wish we had something to do.'\n",
    "initial_text = [char_to_int[c] for c in initial_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GENERATED_LENGTH = 1000\n",
    "test_text = initial_text\n",
    "generated_text = []\n",
    "\n",
    "for i in range(1000):\n",
    "    X = np.reshape(test_text, (1, SEQ_LENGTH, 1))\n",
    "    next_character = model.predict(X/float(VOCABULARY))\n",
    "    index = np.argmax(next_character)\n",
    "    generated_text.append(int_to_char[index])\n",
    "    test_text.append(index)\n",
    "    test_text = test_text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the white rabbit was a little botk of the sable of the garden, the mock turtle said nothing on the soog, and she shought thene was not a moment to be no mistle thing, and she was soomding of the soecs of the gad she was soo mloe ald spok as the mock turtle with a siate oige back on the shate.\n",
      "\n",
      "‘well, it doesn’t kike the bar,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said the king. \n",
      "‘i dan’t remember it,’ said \n"
     ]
    }
   ],
   "source": [
    "print(''.join(generated_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
